{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load ../reader.py\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import xarray as xr\n",
    "import itertools\n",
    "from glob import glob\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "def ncread(sc, filename, mode='single', partitions=None, partition_on='time', **kwargs):\n",
    "    for key, value in kwargs.items():\n",
    "        print(\"%s = %s\" % (key, value))\n",
    "        \n",
    "    if (mode == 'single') and (partition_on == 'time'):\n",
    "        return read_nc_single_time(sc, filename, partitions)\n",
    "    elif (mode == 'single') and (partition_on == 'grid'):\n",
    "        return read_nc_single_grid(sc, filename, partitions)\n",
    "    else:\n",
    "        raise NotImplementedError(\"You specified a mode that is not implemented.\")\n",
    "\n",
    "def nc_multi_read(sc, file_list, partitions=None, data_splitting_mode='slice'):\n",
    "    if (data_splitting_mode == 'slice'):\n",
    "        return read_nc_multi_time_slice(sc, file_list, partitions) \n",
    "        \n",
    "    elif (data_splitting_mode == 'series'):\n",
    "        return read_nc_multi_series(sc, file_list, partitions) \n",
    "    else:\n",
    "        raise NotImplementedError(\"You specified a mode that is not implemented.\")\n",
    "\n",
    "def read_nc_single_time(sc, filename, partitions):\n",
    "    dset = xr.open_dataset(filename)\n",
    "\n",
    "    # Get all time steps\n",
    "    timesteps = dset.time\n",
    "\n",
    "    if not partitions:\n",
    "        partitions = timesteps.size / 6\n",
    "\n",
    "    if partitions > timesteps.size:\n",
    "        partitions = timesteps.size\n",
    "\n",
    "    rdd = sc.parallelize(timesteps.values, partitions)\\\n",
    "            .map(lambda x: readone_timestep(dset, x))\n",
    "\n",
    "    return rdd \n",
    "\n",
    "def readone_timestep(dset, timestep):\n",
    "    chunk = dset.sel(time=timestep)\n",
    "    return chunk\n",
    "\n",
    "\n",
    "def read_nc_single_grid(sc, filename, partitions):\n",
    "     \n",
    "    dset = xr.open_dataset(filename)\n",
    "\n",
    "    # Get latitude and longitude values\n",
    "    lats = dset.lat.values\n",
    "    lons = dset.lon.values\n",
    "    grid_points = [element for element in itertools.product(lats, lons)]\n",
    "\n",
    "    if not partitions:\n",
    "        partitions = len(grid_points) / 20 \n",
    "\n",
    "    if partitions > len(grid_points):\n",
    "        partitions = len(grid_points)\n",
    "\n",
    "    rdd = sc.parallelize(grid_points, partitions)\\\n",
    "            .map(lambda x: readone_gridpoint(dset, x))\n",
    "\n",
    "    return rdd\n",
    "\n",
    "\n",
    "def readone_gridpoint(dset, grid_point):\n",
    "    chunk = dset.sel(lat=grid_point[0], lon=grid_point[1])\n",
    "    return chunk\n",
    "\n",
    "def read_nc_multi_time_slice(sc, paths, partitions):\n",
    "    if isinstance(paths, list):\n",
    "        file_list = paths\n",
    "    elif isinstance(paths, str):\n",
    "        file_list = sorted(glob(paths))\n",
    "    \n",
    "    if not partitions:\n",
    "        partitions = len(file_list) / 20\n",
    "\n",
    "    if partitions > len(file_list):\n",
    "        partitions = len(file_list)\n",
    "\n",
    "    rdd = sc.parallelize(file_list, partitions)\\\n",
    "           .map(lambda filename: readones(filename))\n",
    "\n",
    "    return rdd\n",
    "        \n",
    "def readones(filename):\n",
    "    dset = xr.open_dataset(filename)\n",
    "    return dset\n",
    "\n",
    "def read_nc_multi_series(sc, file_list, partitions):\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def testing():\n",
    "    spark = SparkSession.builder.appName('hi').getOrCreate()\n",
    "    sc = spark.sparkContext\n",
    "    \n",
    "    filename = '/home/abanihi/Documents/climate-data/ERM/t85.an.sfc/e4moda.an.sfc.t85.sst.1957-2002.nc'\n",
    "\n",
    "    #rdd = ncread(sc, filename, mode='single', partition_on='grid').cache()\n",
    "    #print(rdd.count())\n",
    "    #print(rdd.first())\n",
    "    #print(rdd.getNumPartitions())\n",
    "    #print(('################'))\n",
    "    rdd1 = ncread(sc, filename, mode='single', partition_on='time', dims=['time', 'lat'], blsb='kfgjkfj').cache()\n",
    "    print(rdd1.count())\n",
    "    print(rdd1.first())\n",
    "    print(rdd1.getNumPartitions())\n",
    "    \n",
    "    \"\"\"\n",
    "    filepath = '/Users/abanihi/Documents/netCDF-datasets/NCEP-OI/*.nc'\n",
    "    #rdd = ncread(sc, filepath, mode='multi', partition_on='time')\n",
    "    rdd = nc_multi_read(sc, filepath, data_splitting_mode='slice')\n",
    "    print(rdd.count())\n",
    "    print(type(rdd.first()))\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dims = ['time', 'lat']\n",
      "blsb = kfgjkfj\n",
      "540\n",
      "<xarray.Dataset>\n",
      "Dimensions:     (lat: 128, lon: 256)\n",
      "Coordinates:\n",
      "    time        datetime64[ns] 1957-09-01\n",
      "  * lat         (lat) float32 -88.9277 -87.5387 -86.1415 -84.7424 -83.3426 ...\n",
      "  * lon         (lon) float32 0.0 1.406 2.812 4.218 5.624 7.03 8.436 9.842 ...\n",
      "Data variables:\n",
      "    gw          (lat) float32 0.000449381 0.00104581 0.0016425 0.00223829 ...\n",
      "    date        int32 19570901\n",
      "    datesec     int32 0\n",
      "    yyyymmddhh  int32 1957090100\n",
      "    SST         (lat, lon) float64 nan nan nan nan nan nan nan nan nan nan ...\n",
      "Attributes:\n",
      "    title:                     \\nERA40 T85 Surface Analysis: created at NCAR\n",
      "    temporal_span:             \\nThe entire ERA40 archive spans 45 years: Sep...\n",
      "    source_original:           \\nEuropean Center for Medium-Range Weather For...\n",
      "    story:                     \\nThis dataset is a netCDF version of ds126.0 ...\n",
      "    source_NCAR:               \\nData Support Section                        ...\n",
      "    source_format:             \\nThe original ECMWF and the derived T85 are i...\n",
      "    source_file:               \\nMSS: /DSS/U82386\n",
      "    source_availability:       \\nThe ERA-40 data are available for non-commer...\n",
      "    netCDF_creation:           \\nClimate Analysis Section                    ...\n",
      "    netCDF_creation_software:  \\nNCAR Command Language (NCL)                 ...\n",
      "    netCDF_creation_date:      \\nThu Mar 31 21:07:32 MST 2005\n",
      "    Conventions:               CF\n",
      "    history:                   Fri Apr  1 11:51:15 2005: ncrcat /era40/ds126....\n",
      "    nco_openmp_thread_number:  1\n",
      "90\n",
      "CPU times: user 72 ms, sys: 0 ns, total: 72 ms\n",
      "Wall time: 4.3 s\n"
     ]
    }
   ],
   "source": [
    "%time testing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
