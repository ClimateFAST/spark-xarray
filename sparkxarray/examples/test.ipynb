{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import xarray as xr\n",
    "import itertools\n",
    "from glob import glob\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "def ncread(sc, paths, mode='single', **kwargs):\n",
    "    \"\"\"Calls sparkxarray netcdf read function based on the mode parameter.\n",
    "\n",
    "    ============ ==============================\n",
    "    Mode          Reading Function\n",
    "    ------------ ------------------------------\n",
    "    single       : read_nc_single\n",
    "    multi        : read_nc_multi\n",
    "    Anything else: Throw an exception\n",
    "    ============= ==============================\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    sc       :  sparkContext object\n",
    "\n",
    "    paths    :  str or sequence\n",
    "                Either a string glob in the form \"path/to/my/files/*.nc\" or an explicit\n",
    "                list of files to open\n",
    "\n",
    "    mode     : str\n",
    "               'single' for a single file\n",
    "               'multi' for multiple files\n",
    "\n",
    "    **kwargs : dict\n",
    "               partitioning options to be passed on to the actual read function.\n",
    "            \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    if 'partitions' not in kwargs:\n",
    "        kwargs['partitions'] = None\n",
    "\n",
    "    if 'partition_on' not in kwargs:\n",
    "        kwargs['partition_on'] = ['time']\n",
    "\n",
    "    error_msg = (\"You specified a mode that is not implemented.\")\n",
    "\n",
    "    if (mode == 'single'):\n",
    "        return read_nc_single(sc, paths, **kwargs)\n",
    "\n",
    "    elif (mode == 'multi'):\n",
    "        return read_nc_multi(sc, paths, **kwargs)\n",
    "    else:\n",
    "        raise NotImplementedError(error_msg)\n",
    "\n",
    "        \n",
    "def read_nc_single(sc, paths, **kwargs):\n",
    "    \"\"\" Read a single netCDF file\n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "    sc       :  sparkContext object\n",
    "\n",
    "    paths    :  str\n",
    "                an explicit filename to open\n",
    "    \n",
    "\n",
    "    **kwargs : dict\n",
    "               Additional arguments for partitioning \n",
    "\n",
    "    \"\"\"\n",
    "    partition_on = kwargs.get('partition_on')\n",
    "    partitions = kwargs.get('partitions')\n",
    "\n",
    "    dset = xr.open_dataset(paths)\n",
    "\n",
    "    # D = {'dim_1': dim_1_size, 'dim_2': dim_2_size, ...}\n",
    "    D ={dset[dimension].name:dset[dimension].size for dimension in partition_on}\n",
    "    \n",
    "    # dim_sizes = [range(dim_1_size), range(dim_2_size), range(...)]\n",
    "    dim_ranges = [range(dim_size) for dim_size in D.values()]\n",
    "    \n",
    "\n",
    "    dim_cartesian_product_indices = [element for element in itertools.product(*dim_ranges)]\n",
    "\n",
    "    # create a list of dictionaries for  positional indexing\n",
    "    positional_indices = [dict(zip(partition_on, ij)) for ij in dim_cartesian_product_indices]\n",
    "\n",
    "    if not partitions:\n",
    "        partitions = len(dim_cartesian_product_indices) / 50\n",
    "\n",
    "    if partitions > len(dim_cartesian_product_indices):\n",
    "        partitions = len(dim_cartesian_product_indices)\n",
    "\n",
    "    \n",
    "    # Create an RDD\n",
    "    rdd = sc.parallelize(positional_indices, partitions).map(lambda x: readone_slice(dset, x))\n",
    "\n",
    "    return rdd\n",
    "\n",
    "\n",
    "def readone_slice(dset, positional_indices):\n",
    "    \"\"\"Read a slice from an xarray.Dataset.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    dset                : file_object\n",
    "                         xarray.Dataset object\n",
    "    positional_indices  : dict\n",
    "                          dict containing positional indices for each dimension\n",
    "                          e.g. {'lat': 0, 'lon': 0}\n",
    "\n",
    "    Returns\n",
    "    ---------\n",
    "    chunk               : xarray.Dataset\n",
    "                         a subset of the Xarray Dataset\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Change the positional indices into slice objects\n",
    "    # e.g {'lat': 0, 'lon': 0} ---> {'lat': slice(0, 1, None),  'lon': slice(0, 1, None)}\n",
    "    positional_slices = {dim: slice(positional_indices[dim], positional_indices[dim]+1) \n",
    "                                                         for dim in positional_indices}\n",
    "\n",
    "    # Read a slice for the given positional_slices\n",
    "    chunk = dset[positional_slices]\n",
    "    return chunk\n",
    "\n",
    "\n",
    "def read_nc_multi(sc, paths, **kwargs):\n",
    "    \"\"\" Read multiple netCDF files\n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "    sc       :  sparkContext object\n",
    "\n",
    "    paths    :  str or sequence\n",
    "                Either a string glob in the form \"path/to/my/files/*.nc\" or an explicit\n",
    "                list of files to open\n",
    "\n",
    "    **kwargs : dict\n",
    "               Additional arguments for partitioning \n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    partition_on = kwargs.get('partition_on')\n",
    "    partitions = kwargs.get('partitions')\n",
    "\n",
    "    dset = xr.open_mfdataset(paths, autoclose=True)\n",
    "\n",
    "    # D = {'dim_1': dim_1_size, 'dim_2': dim_2_size, ...}\n",
    "    D ={dset[dimension].name:dset[dimension].size for dimension in partition_on}\n",
    "    \n",
    "    # dim_sizes = [range(dim_1_size), range(dim_2_size), range(...)]\n",
    "    dim_ranges = [range(dim_size) for dim_size in D.values()]\n",
    "    \n",
    "\n",
    "    dim_cartesian_product_indices = [element for element in itertools.product(*dim_ranges)]\n",
    "\n",
    "    # create a list of dictionaries for  positional indexing\n",
    "    positional_indices = [dict(zip(partition_on, ij)) for ij in dim_cartesian_product_indices]\n",
    "\n",
    "    if not partitions:\n",
    "        partitions = len(dim_cartesian_product_indices) / 50\n",
    "\n",
    "    if partitions > len(dim_cartesian_product_indices):\n",
    "        partitions = len(dim_cartesian_product_indices)\n",
    "\n",
    "    \n",
    "    # Create an RDD\n",
    "    rdd = sc.parallelize(positional_indices, partitions).map(lambda x: readone_slice(dset, x))\n",
    "\n",
    "    return rdd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('hi').getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " filename = '/home/abanihi/Documents/climate-data/ERM/t85.an.sfc/e4moda.an.sfc.t85.sst.1957-2002.nc'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "def ncread(sc, filename, mode='single', **kwargs):\n",
    "\n",
    "    if 'partitions' not in kwargs:\n",
    "        kwargs['partitions'] = None\n",
    "    if 'partition_on' not in kwargs:\n",
    "        kwargs['partition_on'] = ['time']\n",
    "\n",
    "\n",
    "    if (mode == 'single'):\n",
    "        print('Calling ... read_nc_single(sc, filename, **kwargs)\\n')\n",
    "        print('*******************************')\n",
    "        return read_nc_single(sc, filename, **kwargs)\n",
    "       \n",
    "    elif (mode == 'multi'):\n",
    "        #print('Calling: ...read_nc_multi(sc, filename, **kwargs)')\n",
    "        return read_nc_multi(sc, filename, **kwargs)\n",
    "    else:\n",
    "        raise NotImplementedError(\"You specified a mode that is not implemented.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 136 ms, sys: 24 ms, total: 160 ms\n",
      "Wall time: 391 ms\n"
     ]
    }
   ],
   "source": [
    "%time rdd = ncread(sc, filename, mode='single', partition_on=['lat', 'lon'], partitions=700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 112 ms, sys: 24 ms, total: 136 ms\n",
      "Wall time: 37.8 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "32768"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time rdd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:     (lat: 1, lon: 1, time: 540)\n",
       "Coordinates:\n",
       "  * time        (time) datetime64[ns] 1957-09-01 1957-10-01 1957-11-01 ...\n",
       "  * lat         (lat) float32 -88.9277\n",
       "  * lon         (lon) float32 0.0\n",
       "Data variables:\n",
       "    gw          (lat) float32 0.000449381\n",
       "    date        (time) int32 19570901 19571001 19571101 19571201 19580101 ...\n",
       "    datesec     (time) int32 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...\n",
       "    yyyymmddhh  (time) int32 1957090100 1957100100 1957110100 1957120100 ...\n",
       "    SST         (time, lat, lon) float64 nan nan nan nan nan nan nan nan nan ...\n",
       "Attributes:\n",
       "    title:                     \\nERA40 T85 Surface Analysis: created at NCAR\n",
       "    temporal_span:             \\nThe entire ERA40 archive spans 45 years: Sep...\n",
       "    source_original:           \\nEuropean Center for Medium-Range Weather For...\n",
       "    story:                     \\nThis dataset is a netCDF version of ds126.0 ...\n",
       "    source_NCAR:               \\nData Support Section                        ...\n",
       "    source_format:             \\nThe original ECMWF and the derived T85 are i...\n",
       "    source_file:               \\nMSS: /DSS/U82386\n",
       "    source_availability:       \\nThe ERA-40 data are available for non-commer...\n",
       "    netCDF_creation:           \\nClimate Analysis Section                    ...\n",
       "    netCDF_creation_software:  \\nNCAR Command Language (NCL)                 ...\n",
       "    netCDF_creation_date:      \\nThu Mar 31 21:07:32 MST 2005\n",
       "    Conventions:               CF\n",
       "    history:                   Fri Apr  1 11:51:15 2005: ncrcat /era40/ds126....\n",
       "    nco_openmp_thread_number:  1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "paths = \"/home/abanihi/Documents/climate-data/sparkxarray-tests/*.nc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rddmulti = ncread(sc, paths, mode='multi',partition_on=['lat', 'lon', 'nv'], partitions=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 136 ms, sys: 68 ms, total: 204 ms\n",
      "Wall time: 38.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "32040"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time rddmulti.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:   (lat: 1, lon: 1, nv: 1, time: 4, zlev: 1)\n",
       "Coordinates:\n",
       "  * zlev      (zlev) float32 0.0\n",
       "  * lat       (lat) float32 -88.0\n",
       "  * lon       (lon) float32 0.0\n",
       "  * time      (time) datetime64[ns] 1854-01-15 1854-02-15 1854-03-15 1854-04-15\n",
       "Dimensions without coordinates: nv\n",
       "Data variables:\n",
       "    lat_bnds  (time, lat, nv) float32 -89.0 -89.0 -89.0 -89.0\n",
       "    lon_bnds  (time, lon, nv) float32 -1.0 -1.0 -1.0 -1.0\n",
       "    sst       (time, zlev, lat, lon) float64 nan nan nan nan\n",
       "    anom      (time, zlev, lat, lon) float64 nan nan nan nan\n",
       "Attributes:\n",
       "    Conventions:                CF-1.6\n",
       "    Metadata_Conventions:       CF-1.6, Unidata Dataset Discovery v1.0\n",
       "    metadata_link:              C00884\n",
       "    id:                         ersst.v4.185401\n",
       "    naming_authority:           gov.noaa.ncdc\n",
       "    title:                      NOAA Extended Reconstructed Sea Surface Tempe...\n",
       "    summary:                    ERSST.v4 is developped based on v3b after rev...\n",
       "    institution:                NOAA/NESDIS/NCDC\n",
       "    creator_name:               Boyin Huang\n",
       "    creator_email:              boyin.huang@noaa.gov\n",
       "    date_created:               2014-10-24\n",
       "    production_version:         Beta Version 4\n",
       "    history:                    Version 4 based on Version 3b\n",
       "    publisher_name:             Boyin Huang\n",
       "    publisher_email:            boyin.huang@noaa.gov\n",
       "    publisher_url:              http://www.ncdc.noaa.gov\n",
       "    creator_url:                http://www.ncdc.noaa.gov\n",
       "    license:                    No constraints on data access or use\n",
       "    time_coverage_start:        1854-01-15T000000Z\n",
       "    time_coverage_end:          1854-01-15T000000Z\n",
       "    geospatial_lon_min:         -1.0f\n",
       "    geospatial_lon_max:         359.0f\n",
       "    geospatial_lat_min:         -89.0f\n",
       "    geospatial_lat_max:         89.0f\n",
       "    geospatial_lat_units:       degrees_north\n",
       "    geospatial_lat_resolution:  2.0\n",
       "    geospatial_lon_units:       degrees_east\n",
       "    geospatial_lon_resolution:  2.0\n",
       "    spatial_resolution:         2.0 degree grid\n",
       "    cdm_data_type:              Grid\n",
       "    processing_level:           L4\n",
       "    standard_name_vocabulary:   CF Standard Name Table v27\n",
       "    keywords:                   Earth Science &gt; Oceans &gt; Ocean Temperat...\n",
       "    keywords_vocabulary:        NASA Global Change Master Directory (GCMD) Sc...\n",
       "    project:                    NOAA Extended Reconstructed Sea Surface Tempe...\n",
       "    platform:                   Ship and Buoy SSTs from ICOADS R2.5 and NCEP GTS\n",
       "    instrument:                 Conventional thermometers\n",
       "    source:                     ICOADS R2.5 SST, NCEP GTS SST, HadISST ice, N...\n",
       "    comment:                    SSTs were observed by conventional thermomete...\n",
       "    references:                 Huang et al, 2014: Extended Reconstructed Sea...\n",
       "    climatology:                Climatology is based on 1971-2000 SST, Xue, Y...\n",
       "    description:                In situ data: ICOADS2.5 before 2007 and NCEP ..."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rddmulti.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dset = xr.open_mfdataset(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0009639188647270203"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset.nbytes * (2**-30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13184790313243866"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.nbytes * (2**-30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:     (lat: 1, lon: 1, time: 540)\n",
       "Coordinates:\n",
       "  * time        (time) datetime64[ns] 1957-09-01 1957-10-01 1957-11-01 ...\n",
       "  * lat         (lat) float32 0.700384\n",
       "  * lon         (lon) float32 0.0\n",
       "Data variables:\n",
       "    gw          (lat) float32 0.0244462\n",
       "    date        (time) int32 19570901 19571001 19571101 19571201 19580101 ...\n",
       "    datesec     (time) int32 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...\n",
       "    yyyymmddhh  (time) int32 1957090100 1957100100 1957110100 1957120100 ...\n",
       "    SST         (time, lat, lon) float64 298.0 298.9 300.0 300.8 301.2 301.8 ...\n",
       "Attributes:\n",
       "    title:                     \\nERA40 T85 Surface Analysis: created at NCAR\n",
       "    temporal_span:             \\nThe entire ERA40 archive spans 45 years: Sep...\n",
       "    source_original:           \\nEuropean Center for Medium-Range Weather For...\n",
       "    story:                     \\nThis dataset is a netCDF version of ds126.0 ...\n",
       "    source_NCAR:               \\nData Support Section                        ...\n",
       "    source_format:             \\nThe original ECMWF and the derived T85 are i...\n",
       "    source_file:               \\nMSS: /DSS/U82386\n",
       "    source_availability:       \\nThe ERA-40 data are available for non-commer...\n",
       "    netCDF_creation:           \\nClimate Analysis Section                    ...\n",
       "    netCDF_creation_software:  \\nNCAR Command Language (NCL)                 ...\n",
       "    netCDF_creation_date:      \\nThu Mar 31 21:07:32 MST 2005\n",
       "    Conventions:               CF\n",
       "    history:                   Fri Apr  1 11:51:15 2005: ncrcat /era40/ds126....\n",
       "    nco_openmp_thread_number:  1"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.loc[{'lat': slice(0, 1, None), 'lon': slice(0, 1, None)}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 84 ms, sys: 32 ms, total: 116 ms\n",
      "Wall time: 5.66 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "17694720"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time rdd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0, 0)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D = {'time': 540, 'lat': 128, 'lon': 256}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "partition_on=['lat', 'lon']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dim_ranges=(range(5), range(5))\n",
    "c = [element for element in itertools.product(*dim_ranges)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0),\n",
       " (0, 1),\n",
       " (0, 2),\n",
       " (0, 3),\n",
       " (0, 4),\n",
       " (1, 0),\n",
       " (1, 1),\n",
       " (1, 2),\n",
       " (1, 3),\n",
       " (1, 4),\n",
       " (2, 0),\n",
       " (2, 1),\n",
       " (2, 2),\n",
       " (2, 3),\n",
       " (2, 4),\n",
       " (3, 0),\n",
       " (3, 1),\n",
       " (3, 2),\n",
       " (3, 3),\n",
       " (3, 4),\n",
       " (4, 0),\n",
       " (4, 1),\n",
       " (4, 2),\n",
       " (4, 3),\n",
       " (4, 4)]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'lat': 0, 'lon': 0},\n",
       " {'lat': 0, 'lon': 1},\n",
       " {'lat': 0, 'lon': 2},\n",
       " {'lat': 0, 'lon': 3},\n",
       " {'lat': 0, 'lon': 4},\n",
       " {'lat': 1, 'lon': 0},\n",
       " {'lat': 1, 'lon': 1},\n",
       " {'lat': 1, 'lon': 2},\n",
       " {'lat': 1, 'lon': 3},\n",
       " {'lat': 1, 'lon': 4},\n",
       " {'lat': 2, 'lon': 0},\n",
       " {'lat': 2, 'lon': 1},\n",
       " {'lat': 2, 'lon': 2},\n",
       " {'lat': 2, 'lon': 3},\n",
       " {'lat': 2, 'lon': 4},\n",
       " {'lat': 3, 'lon': 0},\n",
       " {'lat': 3, 'lon': 1},\n",
       " {'lat': 3, 'lon': 2},\n",
       " {'lat': 3, 'lon': 3},\n",
       " {'lat': 3, 'lon': 4},\n",
       " {'lat': 4, 'lon': 0},\n",
       " {'lat': 4, 'lon': 1},\n",
       " {'lat': 4, 'lon': 2},\n",
       " {'lat': 4, 'lon': 3},\n",
       " {'lat': 4, 'lon': 4}]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = [dict(zip(partition_on, ij)) for ij in c ]\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'lat': slice(0, 1, None)},\n",
       " {'lon': slice(0, 1, None)},\n",
       " {'lat': slice(0, 1, None)},\n",
       " {'lon': slice(1, 2, None)},\n",
       " {'lat': slice(0, 1, None)},\n",
       " {'lon': slice(2, 3, None)},\n",
       " {'lat': slice(0, 1, None)},\n",
       " {'lon': slice(3, 4, None)},\n",
       " {'lat': slice(0, 1, None)},\n",
       " {'lon': slice(4, 5, None)},\n",
       " {'lat': slice(1, 2, None)},\n",
       " {'lon': slice(0, 1, None)},\n",
       " {'lat': slice(1, 2, None)},\n",
       " {'lon': slice(1, 2, None)},\n",
       " {'lat': slice(1, 2, None)},\n",
       " {'lon': slice(2, 3, None)},\n",
       " {'lat': slice(1, 2, None)},\n",
       " {'lon': slice(3, 4, None)},\n",
       " {'lat': slice(1, 2, None)},\n",
       " {'lon': slice(4, 5, None)},\n",
       " {'lat': slice(2, 3, None)},\n",
       " {'lon': slice(0, 1, None)},\n",
       " {'lat': slice(2, 3, None)},\n",
       " {'lon': slice(1, 2, None)},\n",
       " {'lat': slice(2, 3, None)},\n",
       " {'lon': slice(2, 3, None)},\n",
       " {'lat': slice(2, 3, None)},\n",
       " {'lon': slice(3, 4, None)},\n",
       " {'lat': slice(2, 3, None)},\n",
       " {'lon': slice(4, 5, None)},\n",
       " {'lat': slice(3, 4, None)},\n",
       " {'lon': slice(0, 1, None)},\n",
       " {'lat': slice(3, 4, None)},\n",
       " {'lon': slice(1, 2, None)},\n",
       " {'lat': slice(3, 4, None)},\n",
       " {'lon': slice(2, 3, None)},\n",
       " {'lat': slice(3, 4, None)},\n",
       " {'lon': slice(3, 4, None)},\n",
       " {'lat': slice(3, 4, None)},\n",
       " {'lon': slice(4, 5, None)},\n",
       " {'lat': slice(4, 5, None)},\n",
       " {'lon': slice(0, 1, None)},\n",
       " {'lat': slice(4, 5, None)},\n",
       " {'lon': slice(1, 2, None)},\n",
       " {'lat': slice(4, 5, None)},\n",
       " {'lon': slice(2, 3, None)},\n",
       " {'lat': slice(4, 5, None)},\n",
       " {'lon': slice(3, 4, None)},\n",
       " {'lat': slice(4, 5, None)},\n",
       " {'lon': slice(4, 5, None)}]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[{dim:  slice(element[dim], element[dim]+1)} for element in m for dim in element.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lat slice(0, 1, None)\n",
      "lon slice(0, 1, None)\n",
      "lat slice(0, 1, None)\n",
      "lon slice(1, 2, None)\n",
      "lat slice(0, 1, None)\n",
      "lon slice(2, 3, None)\n",
      "lat slice(0, 1, None)\n",
      "lon slice(3, 4, None)\n",
      "lat slice(0, 1, None)\n",
      "lon slice(4, 5, None)\n",
      "lat slice(1, 2, None)\n",
      "lon slice(0, 1, None)\n",
      "lat slice(1, 2, None)\n",
      "lon slice(1, 2, None)\n",
      "lat slice(1, 2, None)\n",
      "lon slice(2, 3, None)\n",
      "lat slice(1, 2, None)\n",
      "lon slice(3, 4, None)\n",
      "lat slice(1, 2, None)\n",
      "lon slice(4, 5, None)\n",
      "lat slice(2, 3, None)\n",
      "lon slice(0, 1, None)\n",
      "lat slice(2, 3, None)\n",
      "lon slice(1, 2, None)\n",
      "lat slice(2, 3, None)\n",
      "lon slice(2, 3, None)\n",
      "lat slice(2, 3, None)\n",
      "lon slice(3, 4, None)\n",
      "lat slice(2, 3, None)\n",
      "lon slice(4, 5, None)\n",
      "lat slice(3, 4, None)\n",
      "lon slice(0, 1, None)\n",
      "lat slice(3, 4, None)\n",
      "lon slice(1, 2, None)\n",
      "lat slice(3, 4, None)\n",
      "lon slice(2, 3, None)\n",
      "lat slice(3, 4, None)\n",
      "lon slice(3, 4, None)\n",
      "lat slice(3, 4, None)\n",
      "lon slice(4, 5, None)\n",
      "lat slice(4, 5, None)\n",
      "lon slice(0, 1, None)\n",
      "lat slice(4, 5, None)\n",
      "lon slice(1, 2, None)\n",
      "lat slice(4, 5, None)\n",
      "lon slice(2, 3, None)\n",
      "lat slice(4, 5, None)\n",
      "lon slice(3, 4, None)\n",
      "lat slice(4, 5, None)\n",
      "lon slice(4, 5, None)\n"
     ]
    }
   ],
   "source": [
    "for i in m:\n",
    "    for item in i.keys():\n",
    "        print(item, slice(i[item], i[item]+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i, age in enumerate(d['age'] for d in myList):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-136-4bec6b23cd1c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'd' is not defined"
     ]
    }
   ],
   "source": [
    "[{element:slice(value, value+1)} for element, value in d.items() for d in n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'lat': 2, 'lon': 4}, {'lat': 3, 'lon': 6}]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[item for item in enumerate(dictionary for dictionary in n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'age': 1},\n",
       " {'age': 2},\n",
       " {'age': 3},\n",
       " {'age': 4},\n",
       " {'age': 5},\n",
       " {'age': 6},\n",
       " {'age': 7},\n",
       " {'age': 8},\n",
       " {'age': 9}]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myList = [{'age':x} for x in range(1,10)]\n",
    "myList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1\n",
      "1 2\n",
      "2 3\n",
      "3 4\n",
      "4 5\n",
      "5 6\n",
      "6 7\n",
      "7 8\n",
      "8 9\n"
     ]
    }
   ],
   "source": [
    "# Enumerate ages\n",
    "for i, age in enumerate(d['age'] for d in myList): \n",
    "    print (i,age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dfd': 10}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd1.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n =  [{'lat': 2, 'lon': 4}, {'lat': 3, 'lon': 6}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-127-594e47eada8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mD\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-127-594e47eada8f>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mD\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'd' is not defined"
     ]
    }
   ],
   "source": [
    "[{d:slice(D[d])} for D in n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b = {'lat': 2, 'lon': 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['lat', 'lon'])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
